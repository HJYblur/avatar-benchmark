{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756a759d",
   "metadata": {},
   "source": [
    "### File structure under PeopleSnapShot\n",
    "\n",
    "\n",
    "* `consensus.pkl` → the main file containing detected **SMPL pose, shape, and camera parameters** for the subject.\n",
    "  * betas – the shape coefficients (10-D) describing the subject’s static body shape. Identical to standard SMPL shape parameters.\n",
    "  * v_personal – a per-vertex offset array of shape (6890, 3).This stores small corrective displacements from the neutral SMPL template to the person’s fitted mesh (e.g., clothing bulges, hair, etc.).\n",
    "  * When you reconstruct the canonical mesh:\n",
    "  \n",
    "    ```\n",
    "    vertices = smpl_model(betas=betas).vertices[0] + v_personal\n",
    "    ```\n",
    "\n",
    "    you get the personalized “consensus” geometry that best fits all frames for that subject.\n",
    "* `reconstructed_poses.hdf5` — stores per-frame SMPL parameters for the full sequence (same structure but over time).\n",
    "  | Key         | Shape     | Meaning                                                                 |\n",
    "  | ----------- | --------- | ----------------------------------------------------------------------- |\n",
    "  | **`betas`** | (10,)     | Static body-shape coefficients, same for all frames.                    |\n",
    "  | **`pose`**  | (649, 72) | SMPL pose parameters for each of 649 frames (24 joints × 3 axis-angle). |\n",
    "  | **`trans`** | (649, 3)  | Global translation of the body root per frame.                          |\n",
    "\n",
    "* `camera.pkl` — intrinsic/extrinsic camera parameters for projection.\n",
    "* `consensus.obj` — the reconstructed mesh generated from the SMPL params.\n",
    "* `tex-female-3-casual.jpg` — UV texture corresponding to the mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55072f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lemon/Documents/TUD/Thesis/Code/avatar-benchmark'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bbe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['betas', 'v_personal'])\n",
      "betas: <class 'numpy.ndarray'>, shape: (10,)\n",
      "v_personal: <class 'numpy.ndarray'>, shape: (6890, 3)\n"
     ]
    }
   ],
   "source": [
    "# Investigate the SMPL params from the PeopleSnapshot dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "smpl_params_dir = \"data/people_snapshot_public/female-3-casual/consensus.pkl\"\n",
    "with open(smpl_params_dir, \"rb\") as f:\n",
    "    smpl_params = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "print(type(smpl_params))\n",
    "print(smpl_params.keys())\n",
    "\n",
    "for k, v in smpl_params.items():\n",
    "    print(f\"{k}: {type(v)}, shape: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6a6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['betas', 'pose', 'trans']\n",
      "betas: <class 'h5py._hl.dataset.Dataset'>, shape: (10,)\n",
      "pose: <class 'h5py._hl.dataset.Dataset'>, shape: (649, 72)\n",
      "trans: <class 'h5py._hl.dataset.Dataset'>, shape: (649, 3)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File('data/people_snapshot_public/female-3-casual/reconstructed_poses.hdf5', 'r') as f:\n",
    "    print(list(f.keys()))  # typically ['ppose', 'trans']\n",
    "    for k, v in f.items():\n",
    "        print(f\"{k}: {type(v)}, shape: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8b73de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masks: <class 'numpy.ndarray'>, shape: (648, 1080, 1080)\n"
     ]
    }
   ],
   "source": [
    "from src.utils.data_loader import mask_loader\n",
    "mask_dir = \"data/people_snapshot_public/female-3-casual/masks.hdf5\"\n",
    "masks = mask_loader(mask_dir)\n",
    "print(f\"masks: {type(masks)}, shape: {masks.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b9829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas: <class 'torch.Tensor'>, shape: torch.Size([10])\n",
      "thetas: <class 'torch.Tensor'>, shape: torch.Size([649, 72])\n",
      "transl: <class 'torch.Tensor'>, shape: torch.Size([649, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "pt_data = torch.load(\"data/people_snapshot_public/female-3-casual/poses.pt\")\n",
    "for k, v in pt_data.items():\n",
    "    print(f\"{k}: {type(v)}, shape: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61daf40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poses: <class 'numpy.ndarray'>, shape: (320, 72)\n",
      "trans: <class 'numpy.ndarray'>, shape: (320, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# npz_data = np.load(\"../data/female-3-casual/poses.npz\", allow_pickle=True)\n",
    "npz_data = np.load(\"data/anim/aist_demo.npz\", allow_pickle=True)\n",
    "for k, v in npz_data.items():\n",
    "    print(f\"{k}: {type(v)}, shape: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac8f3065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera_k: <class 'numpy.ndarray'>, shape: (5,)\n",
      "[-0.11669534  0.2515035  -0.00090632 -0.00095365 -0.10548419]\n",
      "camera_rt: <class 'numpy.ndarray'>, shape: (3,)\n",
      "[0. 0. 0.]\n",
      "camera_c: <class 'numpy.ndarray'>, shape: (2,)\n",
      "[511.78055391 567.12542926]\n",
      "camera_f: <class 'numpy.ndarray'>, shape: (2,)\n",
      "[2664.22974522 2664.69277422]\n",
      "height: <class 'int'>, shape: N/A\n",
      "1080\n",
      "width: <class 'int'>, shape: N/A\n",
      "1080\n",
      "camera_t: <class 'numpy.ndarray'>, shape: (3,)\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Inverstigate the camera settings\n",
    "import pickle\n",
    "cam = pickle.load(open(\"data/people_snapshot_public/female-1-casual/camera.pkl\", \"rb\"), encoding='latin1')\n",
    "for k, v in cam.items():\n",
    "    print(f\"{k}: {type(v)}, shape: {v.shape if hasattr(v, 'shape') else 'N/A'}\")\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89771eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shape_from_obj(file_path):\n",
    "    try:\n",
    "        vertices = []\n",
    "        faces = []\n",
    "        with open(file_path) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line or line.startswith(\"#\"):\n",
    "                    continue\n",
    "\n",
    "                parts = line.split()\n",
    "                if len(parts) == 0:\n",
    "                    continue\n",
    "\n",
    "                if parts[0] == \"v\":\n",
    "                    vertex = list(map(float, parts[1:]))\n",
    "                    vertices.append(vertex)\n",
    "                elif parts[0] == \"f\":\n",
    "                    # Handle face indices (OBJ format can have vertex/texture/normal)\n",
    "                    face = []\n",
    "                    for part in parts[1:]:\n",
    "                        # Split by '/' and take the first index (vertex index)\n",
    "                        vertex_idx = int(part.split(\"/\")[0])\n",
    "                        face.append(vertex_idx)\n",
    "                    faces.append(face)\n",
    "\n",
    "        shape_data = {\"vertices\": vertices, \"faces\": faces}\n",
    "\n",
    "        return shape_data\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{file_path} not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the shape: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6698880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start investigating mesh generated from SMPL parameters...\n",
      "Loaded 6890 vertices and 13776 faces\n",
      "First vertex: [0.171158, -0.709704, 5.285116]\n",
      "First face: [2, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "# Observe SMPL-generated Mesh\n",
    "obj_path = \"../data/female-4-casual/output/embedding.obj\"\n",
    "\n",
    "print(\"Start investigating mesh generated from SMPL parameters...\")\n",
    "obj_data = load_shape_from_obj(obj_path)\n",
    "if obj_data:\n",
    "    print(\n",
    "        f\"Loaded {len(obj_data['vertices'])} vertices and {len(obj_data['faces'])} faces\"\n",
    "    )\n",
    "    print(f\"First vertex: {obj_data['vertices'][0]}\")\n",
    "    print(f\"First face: {obj_data['faces'][0]}\")\n",
    "else:\n",
    "    print(\"Failed to load OBJ file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586229e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating mapping from mesh to Gaussian...\n",
      "Loaded JSON data with keys: ['cano_mesh', 'sample_fidxs', 'sample_bary', '_xyz', '_rotation']\n",
      "cano_mesh: (<class 'str'>, 13)\n",
      "sample_fidxs: (<class 'list'>, 106073)\n",
      "sample_bary: (<class 'list'>, 106073)\n",
      "_xyz: (<class 'list'>, 106073)\n",
      "_rotation: (<class 'list'>, 106073)\n",
      "embedding.obj <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Observe Mesh ==> Gaussian Mapping\n",
    "import json\n",
    "json_path = \"../data/female-4-casual/output/embedding.json\"\n",
    "\n",
    "print(\"Investigating mapping from mesh to Gaussian...\")\n",
    "json_data = json.load(open(json_path))\n",
    "print(f\"Loaded JSON data with keys: {list(json_data.keys())}\")\n",
    "for key in json_data:\n",
    "    print(\n",
    "        f\"{key}: {type(json_data[key]), len(json_data[key]) if hasattr(json_data[key], '__len__') else 'N/A'}\"\n",
    "    )\n",
    "    \n",
    "# List out the cano_mesh elements\n",
    "cano_mesh = json_data.get(\"cano_mesh\", {})\n",
    "if cano_mesh:\n",
    "    print(cano_mesh, type(cano_mesh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f09977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating animation .npz file structure...\n",
      "Loaded .npz file with keys: ['betas', 'global_orient', 'body_pose', 'transl']\n",
      "betas: (<class 'numpy.ndarray'>, (1, 10))\n",
      "global_orient: (<class 'numpy.ndarray'>, (51, 3))\n",
      "body_pose: (<class 'numpy.ndarray'>, (51, 69))\n",
      "transl: (<class 'numpy.ndarray'>, (51, 3))\n"
     ]
    }
   ],
   "source": [
    "# Observe Animation file structure(.npz)\n",
    "# It covers SMPL parameters per frame\n",
    "import numpy as np \n",
    "npz_path = \"../data/female-3-casual/poses/anim_nerf_test.npz\"\n",
    "\n",
    "print(\"Investigating animation .npz file structure...\")\n",
    "npz_data = np.load(npz_path)\n",
    "print(f\"Loaded .npz file with keys: {list(npz_data.keys())}\")\n",
    "for key in npz_data:\n",
    "    print(\n",
    "        f\"{key}: {type(npz_data[key]), npz_data[key].shape if hasattr(npz_data[key], 'shape') else 'N/A'}\"\n",
    "    )   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smpl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
