{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756a759d",
   "metadata": {},
   "source": [
    "### File structure under PeopleSnapShot\n",
    "\n",
    "\n",
    "* `consensus.pkl` → the main file containing detected **SMPL pose, shape, and camera parameters** for the subject.\n",
    "  * betas – the shape coefficients (10-D) describing the subject’s static body shape. Identical to standard SMPL shape parameters.\n",
    "  * v_personal – a per-vertex offset array of shape (6890, 3).This stores small corrective displacements from the neutral SMPL template to the person’s fitted mesh (e.g., clothing bulges, hair, etc.).\n",
    "  * When you reconstruct the canonical mesh:\n",
    "  \n",
    "    ```\n",
    "    vertices = smpl_model(betas=betas).vertices[0] + v_personal\n",
    "    ```\n",
    "\n",
    "    you get the personalized “consensus” geometry that best fits all frames for that subject.\n",
    "* `reconstructed_poses.hdf5` — stores per-frame SMPL parameters for the full sequence (same structure but over time).\n",
    "  | Key         | Shape     | Meaning                                                                 |\n",
    "  | ----------- | --------- | ----------------------------------------------------------------------- |\n",
    "  | **`betas`** | (10,)     | Static body-shape coefficients, same for all frames.                    |\n",
    "  | **`pose`**  | (649, 72) | SMPL pose parameters for each of 649 frames (24 joints × 3 axis-angle). |\n",
    "  | **`trans`** | (649, 3)  | Global translation of the body root per frame.                          |\n",
    "\n",
    "* `camera.pkl` — intrinsic/extrinsic camera parameters for projection.\n",
    "* `consensus.obj` — the reconstructed mesh generated from the SMPL params.\n",
    "* `tex-female-3-casual.jpg` — UV texture corresponding to the mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55072f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lemon/Documents/TUD/Thesis/Code/avatar-benchmark'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bbe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['betas', 'v_personal'])\n",
      "betas: <class 'numpy.ndarray'>, shape: (10,)\n",
      "v_personal: <class 'numpy.ndarray'>, shape: (6890, 3)\n"
     ]
    }
   ],
   "source": [
    "# Investigate the SMPL params from the PeopleSnapshot dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "smpl_params_dir = \"data/people_snapshot_public/female-3-casual/consensus.pkl\"\n",
    "with open(smpl_params_dir, \"rb\") as f:\n",
    "    smpl_params = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "print(type(smpl_params))\n",
    "print(smpl_params.keys())\n",
    "\n",
    "for k, v in smpl_params.items():\n",
    "    print(f\"{k}: {type(v)}, shape: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6a6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['betas', 'pose', 'trans']\n",
      "betas: <class 'h5py._hl.dataset.Dataset'>, shape: (10,)\n",
      "pose: <class 'h5py._hl.dataset.Dataset'>, shape: (649, 72)\n",
      "trans: <class 'h5py._hl.dataset.Dataset'>, shape: (649, 3)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File('data/people_snapshot_public/female-3-casual/reconstructed_poses.hdf5', 'r') as f:\n",
    "    print(list(f.keys()))  # typically ['ppose', 'trans']\n",
    "    for k, v in f.items():\n",
    "        print(f\"{k}: {type(v)}, shape: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8b73de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masks: <class 'numpy.ndarray'>, shape: (648, 1080, 1080)\n"
     ]
    }
   ],
   "source": [
    "from src.utils.data_loader import mask_loader\n",
    "mask_dir = \"data/people_snapshot_public/female-3-casual/masks.hdf5\"\n",
    "masks = mask_loader(mask_dir)\n",
    "print(f\"masks: {type(masks)}, shape: {masks.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b9829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas: <class 'torch.Tensor'>, shape: torch.Size([10])\n",
      "thetas: <class 'torch.Tensor'>, shape: torch.Size([649, 72])\n",
      "transl: <class 'torch.Tensor'>, shape: torch.Size([649, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "pt_data = torch.load(\"data/people_snapshot_public/female-3-casual/poses.pt\")\n",
    "for k, v in pt_data.items():\n",
    "    print(f\"{k}: {type(v)}, shape: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61daf40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poses: <class 'numpy.ndarray'>, shape: (320, 72)\n",
      "trans: <class 'numpy.ndarray'>, shape: (320, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# npz_data = np.load(\"../data/female-3-casual/poses.npz\", allow_pickle=True)\n",
    "npz_data = np.load(\"data/anim/aist_demo.npz\", allow_pickle=True)\n",
    "for k, v in npz_data.items():\n",
    "    print(f\"{k}: {type(v)}, shape: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f3065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera_k: <class 'numpy.ndarray'>, shape: (5,)\n",
      "[-0.11669534  0.2515035  -0.00090632 -0.00095365 -0.10548419]\n",
      "camera_rt: <class 'numpy.ndarray'>, shape: (3,)\n",
      "[0. 0. 0.]\n",
      "camera_c: <class 'numpy.ndarray'>, shape: (2,)\n",
      "[511.78055391 567.12542926]\n",
      "camera_f: <class 'numpy.ndarray'>, shape: (2,)\n",
      "[2664.22974522 2664.69277422]\n",
      "height: <class 'int'>, shape: N/A\n",
      "1080\n",
      "width: <class 'int'>, shape: N/A\n",
      "1080\n",
      "camera_t: <class 'numpy.ndarray'>, shape: (3,)\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Inverstigate the camera settings\n",
    "import pickle\n",
    "cam = pickle.load(open(\"data/people_snapshot_public/female-1-casual/camera.pkl\", \"rb\"), encoding='latin1')\n",
    "for k, v in cam.items():\n",
    "    print(f\"{k}: {type(v)}, shape: {v.shape if hasattr(v, 'shape') else 'N/A'}\")\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89771eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shape_from_obj(file_path):\n",
    "    try:\n",
    "        vertices = []\n",
    "        faces = []\n",
    "        with open(file_path) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line or line.startswith(\"#\"):\n",
    "                    continue\n",
    "\n",
    "                parts = line.split()\n",
    "                if len(parts) == 0:\n",
    "                    continue\n",
    "\n",
    "                if parts[0] == \"v\":\n",
    "                    vertex = list(map(float, parts[1:]))\n",
    "                    vertices.append(vertex)\n",
    "                elif parts[0] == \"f\":\n",
    "                    # Handle face indices (OBJ format can have vertex/texture/normal)\n",
    "                    face = []\n",
    "                    for part in parts[1:]:\n",
    "                        # Split by '/' and take the first index (vertex index)\n",
    "                        vertex_idx = int(part.split(\"/\")[0])\n",
    "                        face.append(vertex_idx)\n",
    "                    faces.append(face)\n",
    "\n",
    "        shape_data = {\"vertices\": vertices, \"faces\": faces}\n",
    "\n",
    "        return shape_data\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{file_path} not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the shape: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6698880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start investigating mesh generated from SMPL parameters...\n",
      "Loaded 10475 vertices and 20908 faces\n",
      "First vertex: [0.062714, 0.2885, -0.009561]\n",
      "First face: [4, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "# Observe SMPL-generated Mesh\n",
    "# obj_path = \"../data/female-4-casual/output/embedding.obj\"\n",
    "obj_path = \"./models/smplx/smplx_uv.obj\"\n",
    "\n",
    "print(\"Start investigating mesh generated from SMPL parameters...\")\n",
    "obj_data = load_shape_from_obj(obj_path)\n",
    "if obj_data:\n",
    "    print(\n",
    "        f\"Loaded {len(obj_data['vertices'])} vertices and {len(obj_data['faces'])} faces\"\n",
    "    )\n",
    "    print(f\"First vertex: {obj_data['vertices'][0]}\")\n",
    "    print(f\"First face: {obj_data['faces'][0]}\")\n",
    "else:\n",
    "    print(\"Failed to load OBJ file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6963e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh has 11313 vertices and 20908 faces\n",
      "First vertex: [ 0.062714  0.2885   -0.009561]\n",
      "First face: [3 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Use library to load obj file and read its content\n",
    "import trimesh\n",
    "obj_path = \"./models/smplx/smplx_uv.obj\"\n",
    "mesh = trimesh.load(obj_path)\n",
    "print(f\"Mesh has {len(mesh.vertices)} vertices and {len(mesh.faces)} faces\")\n",
    "print(f\"First vertex: {mesh.vertices[0]}\")\n",
    "print(f\"First face: {mesh.faces[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b004190c",
   "metadata": {},
   "source": [
    "### Explanation of the obj file\n",
    "\n",
    "In the vertices section it stores the position of every vertices, then face section stores the three vertices it use to define the face. So the bary-centric center is the average position of the three vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586229e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating mapping from mesh to Gaussian...\n",
      "Loaded JSON data with keys: ['cano_mesh', 'sample_fidxs', 'sample_bary', '_xyz', '_rotation']\n",
      "cano_mesh: (<class 'str'>, 13)\n",
      "sample_fidxs: (<class 'list'>, 106073)\n",
      "sample_bary: (<class 'list'>, 106073)\n",
      "_xyz: (<class 'list'>, 106073)\n",
      "_rotation: (<class 'list'>, 106073)\n",
      "embedding.obj <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Observe Mesh ==> Gaussian Mapping\n",
    "import json\n",
    "json_path = \"../data/female-4-casual/output/embedding.json\"\n",
    "\n",
    "print(\"Investigating mapping from mesh to Gaussian...\")\n",
    "json_data = json.load(open(json_path))\n",
    "print(f\"Loaded JSON data with keys: {list(json_data.keys())}\")\n",
    "for key in json_data:\n",
    "    print(\n",
    "        f\"{key}: {type(json_data[key]), len(json_data[key]) if hasattr(json_data[key], '__len__') else 'N/A'}\"\n",
    "    )\n",
    "    \n",
    "# List out the cano_mesh elements\n",
    "cano_mesh = json_data.get(\"cano_mesh\", {})\n",
    "if cano_mesh:\n",
    "    print(cano_mesh, type(cano_mesh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f09977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating animation .npz file structure...\n",
      "Loaded .npz file with keys: ['betas', 'global_orient', 'body_pose', 'transl']\n",
      "betas: (<class 'numpy.ndarray'>, (1, 10))\n",
      "global_orient: (<class 'numpy.ndarray'>, (51, 3))\n",
      "body_pose: (<class 'numpy.ndarray'>, (51, 69))\n",
      "transl: (<class 'numpy.ndarray'>, (51, 3))\n"
     ]
    }
   ],
   "source": [
    "# Observe Animation file structure(.npz)\n",
    "# It covers SMPL parameters per frame\n",
    "import numpy as np \n",
    "npz_path = \"../data/female-3-casual/poses/anim_nerf_test.npz\"\n",
    "\n",
    "print(\"Investigating animation .npz file structure...\")\n",
    "npz_data = np.load(npz_path)\n",
    "print(f\"Loaded .npz file with keys: {list(npz_data.keys())}\")\n",
    "for key in npz_data:\n",
    "    print(\n",
    "        f\"{key}: {type(npz_data[key]), npz_data[key].shape if hasattr(npz_data[key], 'shape') else 'N/A'}\"\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f07ba28",
   "metadata": {},
   "source": [
    "### Invertigate ply file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4f8c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "def inspect_ply_file(ply_file_path):\n",
    "    plydata = PlyData.read(ply_file_path)\n",
    "    print(f\"Number of elements: {len(plydata.elements)}\")\n",
    "    for element in plydata.elements:\n",
    "        print(f\"Element: {element.name}, count: {element.count}, properties: {element.properties}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8510694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements: 1\n",
      "Element: vertex, count: 83632, properties: (PlyProperty('x', 'float'), PlyProperty('y', 'float'), PlyProperty('z', 'float'), PlyProperty('opacity', 'float'), PlyProperty('parent', 'int'), PlyProperty('f_dc_0', 'float'), PlyProperty('f_dc_1', 'float'), PlyProperty('f_dc_2', 'float'), PlyProperty('f_rest_0', 'float'), PlyProperty('f_rest_1', 'float'), PlyProperty('f_rest_2', 'float'), PlyProperty('f_rest_3', 'float'), PlyProperty('f_rest_4', 'float'), PlyProperty('f_rest_5', 'float'), PlyProperty('f_rest_6', 'float'), PlyProperty('f_rest_7', 'float'), PlyProperty('f_rest_8', 'float'), PlyProperty('f_rest_9', 'float'), PlyProperty('f_rest_10', 'float'), PlyProperty('f_rest_11', 'float'), PlyProperty('f_rest_12', 'float'), PlyProperty('f_rest_13', 'float'), PlyProperty('f_rest_14', 'float'), PlyProperty('f_rest_15', 'float'), PlyProperty('f_rest_16', 'float'), PlyProperty('f_rest_17', 'float'), PlyProperty('f_rest_18', 'float'), PlyProperty('f_rest_19', 'float'), PlyProperty('f_rest_20', 'float'), PlyProperty('f_rest_21', 'float'), PlyProperty('f_rest_22', 'float'), PlyProperty('f_rest_23', 'float'), PlyProperty('f_rest_24', 'float'), PlyProperty('f_rest_25', 'float'), PlyProperty('f_rest_26', 'float'), PlyProperty('f_rest_27', 'float'), PlyProperty('f_rest_28', 'float'), PlyProperty('f_rest_29', 'float'), PlyProperty('f_rest_30', 'float'), PlyProperty('f_rest_31', 'float'), PlyProperty('f_rest_32', 'float'), PlyProperty('f_rest_33', 'float'), PlyProperty('f_rest_34', 'float'), PlyProperty('f_rest_35', 'float'), PlyProperty('f_rest_36', 'float'), PlyProperty('f_rest_37', 'float'), PlyProperty('f_rest_38', 'float'), PlyProperty('f_rest_39', 'float'), PlyProperty('f_rest_40', 'float'), PlyProperty('f_rest_41', 'float'), PlyProperty('f_rest_42', 'float'), PlyProperty('f_rest_43', 'float'), PlyProperty('f_rest_44', 'float'), PlyProperty('scale_0', 'float'), PlyProperty('scale_1', 'float'), PlyProperty('scale_2', 'float'), PlyProperty('rot_0', 'float'), PlyProperty('rot_1', 'float'), PlyProperty('rot_2', 'float'), PlyProperty('rot_3', 'float'), PlyProperty('rot_4', 'float'), PlyProperty('rot_5', 'float'), PlyProperty('rot_6', 'float'), PlyProperty('rot_7', 'float'), PlyProperty('rot_8', 'float'))\n"
     ]
    }
   ],
   "source": [
    "inspect_ply_file(\"./models/avatar_template.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91c4ac43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements: 1\n",
      "Element: vertex, count: 3636448, properties: (PlyProperty('x', 'float'), PlyProperty('y', 'float'), PlyProperty('z', 'float'), PlyProperty('nx', 'float'), PlyProperty('ny', 'float'), PlyProperty('nz', 'float'), PlyProperty('f_dc_0', 'float'), PlyProperty('f_dc_1', 'float'), PlyProperty('f_dc_2', 'float'), PlyProperty('f_rest_0', 'float'), PlyProperty('f_rest_1', 'float'), PlyProperty('f_rest_2', 'float'), PlyProperty('f_rest_3', 'float'), PlyProperty('f_rest_4', 'float'), PlyProperty('f_rest_5', 'float'), PlyProperty('f_rest_6', 'float'), PlyProperty('f_rest_7', 'float'), PlyProperty('f_rest_8', 'float'), PlyProperty('f_rest_9', 'float'), PlyProperty('f_rest_10', 'float'), PlyProperty('f_rest_11', 'float'), PlyProperty('f_rest_12', 'float'), PlyProperty('f_rest_13', 'float'), PlyProperty('f_rest_14', 'float'), PlyProperty('f_rest_15', 'float'), PlyProperty('f_rest_16', 'float'), PlyProperty('f_rest_17', 'float'), PlyProperty('f_rest_18', 'float'), PlyProperty('f_rest_19', 'float'), PlyProperty('f_rest_20', 'float'), PlyProperty('f_rest_21', 'float'), PlyProperty('f_rest_22', 'float'), PlyProperty('f_rest_23', 'float'), PlyProperty('f_rest_24', 'float'), PlyProperty('f_rest_25', 'float'), PlyProperty('f_rest_26', 'float'), PlyProperty('f_rest_27', 'float'), PlyProperty('f_rest_28', 'float'), PlyProperty('f_rest_29', 'float'), PlyProperty('f_rest_30', 'float'), PlyProperty('f_rest_31', 'float'), PlyProperty('f_rest_32', 'float'), PlyProperty('f_rest_33', 'float'), PlyProperty('f_rest_34', 'float'), PlyProperty('f_rest_35', 'float'), PlyProperty('f_rest_36', 'float'), PlyProperty('f_rest_37', 'float'), PlyProperty('f_rest_38', 'float'), PlyProperty('f_rest_39', 'float'), PlyProperty('f_rest_40', 'float'), PlyProperty('f_rest_41', 'float'), PlyProperty('f_rest_42', 'float'), PlyProperty('f_rest_43', 'float'), PlyProperty('f_rest_44', 'float'), PlyProperty('opacity', 'float'), PlyProperty('scale_0', 'float'), PlyProperty('scale_1', 'float'), PlyProperty('scale_2', 'float'), PlyProperty('rot_0', 'float'), PlyProperty('rot_1', 'float'), PlyProperty('rot_2', 'float'), PlyProperty('rot_3', 'float'))\n"
     ]
    }
   ],
   "source": [
    "inspect_ply_file(\"./data/gaussian_scene/flowers.ply\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smpl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
